{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikea\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Data\n",
    "\n",
    "The data is located at [https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv](https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv)\n",
    "\n",
    "Dataset Source: [UCI Machine Learning Library](https://archive.ics.uci.edu/dataset/94/spambase)\n",
    "\n",
    "Import the data using Pandas. Display the resulting DataFrame to confirm the import was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  spam  \n",
       "0                       278     1  \n",
       "1                      1028     1  \n",
       "2                      2259     1  \n",
       "3                       191     1  \n",
       "4                       191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "data = pd.read_csv(\"https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Model Performance\n",
    "\n",
    "You will be creating and comparing two models on this data: a Logistic Regression, and a Random Forests Classifier. Before you create, fit, and score the models, make a prediction as to which model you think will perform better. You do not need to be correct! \n",
    "\n",
    "Write down your prediction in the designated cells in your Jupyter Notebook, and provide justification for your educated guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My initial intuition, based on class discussions, says that the Random Forrest will be a better fit and make a better prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the labels set `y` and features DataFrame `X`\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y=data['spam']\n",
    "\n",
    "\n",
    "X=data.copy()\n",
    "X = data.copy()\n",
    "X = X.drop(columns='spam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data['spam']\n",
    "y.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam\n",
       "0    2788\n",
       "1    1813\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of the labels variable (`y`) by using the `value_counts` function.\n",
    "y_values=y.value_counts()\n",
    "y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1151 entries, 3683 to 2095\n",
      "Data columns (total 57 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   word_freq_make              1151 non-null   float64\n",
      " 1   word_freq_address           1151 non-null   float64\n",
      " 2   word_freq_all               1151 non-null   float64\n",
      " 3   word_freq_3d                1151 non-null   float64\n",
      " 4   word_freq_our               1151 non-null   float64\n",
      " 5   word_freq_over              1151 non-null   float64\n",
      " 6   word_freq_remove            1151 non-null   float64\n",
      " 7   word_freq_internet          1151 non-null   float64\n",
      " 8   word_freq_order             1151 non-null   float64\n",
      " 9   word_freq_mail              1151 non-null   float64\n",
      " 10  word_freq_receive           1151 non-null   float64\n",
      " 11  word_freq_will              1151 non-null   float64\n",
      " 12  word_freq_people            1151 non-null   float64\n",
      " 13  word_freq_report            1151 non-null   float64\n",
      " 14  word_freq_addresses         1151 non-null   float64\n",
      " 15  word_freq_free              1151 non-null   float64\n",
      " 16  word_freq_business          1151 non-null   float64\n",
      " 17  word_freq_email             1151 non-null   float64\n",
      " 18  word_freq_you               1151 non-null   float64\n",
      " 19  word_freq_credit            1151 non-null   float64\n",
      " 20  word_freq_your              1151 non-null   float64\n",
      " 21  word_freq_font              1151 non-null   float64\n",
      " 22  word_freq_000               1151 non-null   float64\n",
      " 23  word_freq_money             1151 non-null   float64\n",
      " 24  word_freq_hp                1151 non-null   float64\n",
      " 25  word_freq_hpl               1151 non-null   float64\n",
      " 26  word_freq_george            1151 non-null   float64\n",
      " 27  word_freq_650               1151 non-null   float64\n",
      " 28  word_freq_lab               1151 non-null   float64\n",
      " 29  word_freq_labs              1151 non-null   float64\n",
      " 30  word_freq_telnet            1151 non-null   float64\n",
      " 31  word_freq_857               1151 non-null   float64\n",
      " 32  word_freq_data              1151 non-null   float64\n",
      " 33  word_freq_415               1151 non-null   float64\n",
      " 34  word_freq_85                1151 non-null   float64\n",
      " 35  word_freq_technology        1151 non-null   float64\n",
      " 36  word_freq_1999              1151 non-null   float64\n",
      " 37  word_freq_parts             1151 non-null   float64\n",
      " 38  word_freq_pm                1151 non-null   float64\n",
      " 39  word_freq_direct            1151 non-null   float64\n",
      " 40  word_freq_cs                1151 non-null   float64\n",
      " 41  word_freq_meeting           1151 non-null   float64\n",
      " 42  word_freq_original          1151 non-null   float64\n",
      " 43  word_freq_project           1151 non-null   float64\n",
      " 44  word_freq_re                1151 non-null   float64\n",
      " 45  word_freq_edu               1151 non-null   float64\n",
      " 46  word_freq_table             1151 non-null   float64\n",
      " 47  word_freq_conference        1151 non-null   float64\n",
      " 48  char_freq_;                 1151 non-null   float64\n",
      " 49  char_freq_(                 1151 non-null   float64\n",
      " 50  char_freq_[                 1151 non-null   float64\n",
      " 51  char_freq_!                 1151 non-null   float64\n",
      " 52  char_freq_$                 1151 non-null   float64\n",
      " 53  char_freq_#                 1151 non-null   float64\n",
      " 54  capital_run_length_average  1151 non-null   float64\n",
      " 55  capital_run_length_longest  1151 non-null   int64  \n",
      " 56  capital_run_length_total    1151 non-null   int64  \n",
      "dtypes: float64(55), int64(2)\n",
      "memory usage: 521.5 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.110565</td>\n",
       "      <td>0.242606</td>\n",
       "      <td>0.278836</td>\n",
       "      <td>0.085004</td>\n",
       "      <td>0.332268</td>\n",
       "      <td>0.103640</td>\n",
       "      <td>0.131607</td>\n",
       "      <td>0.106638</td>\n",
       "      <td>0.096898</td>\n",
       "      <td>0.245847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>0.041666</td>\n",
       "      <td>0.130391</td>\n",
       "      <td>0.016555</td>\n",
       "      <td>0.269250</td>\n",
       "      <td>0.077579</td>\n",
       "      <td>0.047875</td>\n",
       "      <td>5.538787</td>\n",
       "      <td>48.605560</td>\n",
       "      <td>294.531712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.314554</td>\n",
       "      <td>1.397329</td>\n",
       "      <td>0.485986</td>\n",
       "      <td>1.665661</td>\n",
       "      <td>0.664382</td>\n",
       "      <td>0.297883</td>\n",
       "      <td>0.462125</td>\n",
       "      <td>0.376932</td>\n",
       "      <td>0.287065</td>\n",
       "      <td>0.668625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306060</td>\n",
       "      <td>0.259371</td>\n",
       "      <td>0.194040</td>\n",
       "      <td>0.135919</td>\n",
       "      <td>0.594141</td>\n",
       "      <td>0.274745</td>\n",
       "      <td>0.603709</td>\n",
       "      <td>31.715040</td>\n",
       "      <td>119.314035</td>\n",
       "      <td>700.284226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.285000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>102.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.672500</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>4.230000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>4.367000</td>\n",
       "      <td>1.932000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>8.333000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>1333.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     1151.000000        1151.000000    1151.000000   1151.000000   \n",
       "mean         0.110565           0.242606       0.278836      0.085004   \n",
       "std          0.314554           1.397329       0.485986      1.665661   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.440000      0.000000   \n",
       "max          4.000000          14.280000       4.340000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    1151.000000     1151.000000       1151.000000         1151.000000   \n",
       "mean        0.332268        0.103640          0.131607            0.106638   \n",
       "std         0.664382        0.297883          0.462125            0.376932   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.450000        0.000000          0.000000            0.000000   \n",
       "max         9.090000        3.570000          7.270000            4.230000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  word_freq_conference  \\\n",
       "count      1151.000000     1151.000000  ...           1151.000000   \n",
       "mean          0.096898        0.245847  ...              0.031008   \n",
       "std           0.287065        0.668625  ...              0.306060   \n",
       "min           0.000000        0.000000  ...              0.000000   \n",
       "25%           0.000000        0.000000  ...              0.000000   \n",
       "50%           0.000000        0.000000  ...              0.000000   \n",
       "75%           0.000000        0.175000  ...              0.000000   \n",
       "max           3.230000       11.110000  ...              8.330000   \n",
       "\n",
       "       char_freq_;  char_freq_(  char_freq_[  char_freq_!  char_freq_$  \\\n",
       "count  1151.000000  1151.000000  1151.000000  1151.000000  1151.000000   \n",
       "mean      0.041666     0.130391     0.016555     0.269250     0.077579   \n",
       "std       0.259371     0.194040     0.135919     0.594141     0.274745   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.065000     0.000000     0.010000     0.000000   \n",
       "75%       0.000000     0.189000     0.000000     0.328500     0.052000   \n",
       "max       4.367000     1.932000     4.081000     8.333000     5.300000   \n",
       "\n",
       "       char_freq_#  capital_run_length_average  capital_run_length_longest  \\\n",
       "count  1151.000000                 1151.000000                 1151.000000   \n",
       "mean      0.047875                    5.538787                   48.605560   \n",
       "std       0.603709                   31.715040                  119.314035   \n",
       "min       0.000000                    1.000000                    1.000000   \n",
       "25%       0.000000                    1.600000                    7.000000   \n",
       "50%       0.000000                    2.285000                   15.000000   \n",
       "75%       0.000000                    3.672500                   44.000000   \n",
       "max      19.829000                  667.000000                 1333.000000   \n",
       "\n",
       "       capital_run_length_total  \n",
       "count               1151.000000  \n",
       "mean                 294.531712  \n",
       "std                  700.284226  \n",
       "min                    1.000000  \n",
       "25%                   40.000000  \n",
       "50%                  102.000000  \n",
       "75%                  272.000000  \n",
       "max                15841.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.info()\n",
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3450 entries, 1173 to 860\n",
      "Data columns (total 57 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   word_freq_make              3450 non-null   float64\n",
      " 1   word_freq_address           3450 non-null   float64\n",
      " 2   word_freq_all               3450 non-null   float64\n",
      " 3   word_freq_3d                3450 non-null   float64\n",
      " 4   word_freq_our               3450 non-null   float64\n",
      " 5   word_freq_over              3450 non-null   float64\n",
      " 6   word_freq_remove            3450 non-null   float64\n",
      " 7   word_freq_internet          3450 non-null   float64\n",
      " 8   word_freq_order             3450 non-null   float64\n",
      " 9   word_freq_mail              3450 non-null   float64\n",
      " 10  word_freq_receive           3450 non-null   float64\n",
      " 11  word_freq_will              3450 non-null   float64\n",
      " 12  word_freq_people            3450 non-null   float64\n",
      " 13  word_freq_report            3450 non-null   float64\n",
      " 14  word_freq_addresses         3450 non-null   float64\n",
      " 15  word_freq_free              3450 non-null   float64\n",
      " 16  word_freq_business          3450 non-null   float64\n",
      " 17  word_freq_email             3450 non-null   float64\n",
      " 18  word_freq_you               3450 non-null   float64\n",
      " 19  word_freq_credit            3450 non-null   float64\n",
      " 20  word_freq_your              3450 non-null   float64\n",
      " 21  word_freq_font              3450 non-null   float64\n",
      " 22  word_freq_000               3450 non-null   float64\n",
      " 23  word_freq_money             3450 non-null   float64\n",
      " 24  word_freq_hp                3450 non-null   float64\n",
      " 25  word_freq_hpl               3450 non-null   float64\n",
      " 26  word_freq_george            3450 non-null   float64\n",
      " 27  word_freq_650               3450 non-null   float64\n",
      " 28  word_freq_lab               3450 non-null   float64\n",
      " 29  word_freq_labs              3450 non-null   float64\n",
      " 30  word_freq_telnet            3450 non-null   float64\n",
      " 31  word_freq_857               3450 non-null   float64\n",
      " 32  word_freq_data              3450 non-null   float64\n",
      " 33  word_freq_415               3450 non-null   float64\n",
      " 34  word_freq_85                3450 non-null   float64\n",
      " 35  word_freq_technology        3450 non-null   float64\n",
      " 36  word_freq_1999              3450 non-null   float64\n",
      " 37  word_freq_parts             3450 non-null   float64\n",
      " 38  word_freq_pm                3450 non-null   float64\n",
      " 39  word_freq_direct            3450 non-null   float64\n",
      " 40  word_freq_cs                3450 non-null   float64\n",
      " 41  word_freq_meeting           3450 non-null   float64\n",
      " 42  word_freq_original          3450 non-null   float64\n",
      " 43  word_freq_project           3450 non-null   float64\n",
      " 44  word_freq_re                3450 non-null   float64\n",
      " 45  word_freq_edu               3450 non-null   float64\n",
      " 46  word_freq_table             3450 non-null   float64\n",
      " 47  word_freq_conference        3450 non-null   float64\n",
      " 48  char_freq_;                 3450 non-null   float64\n",
      " 49  char_freq_(                 3450 non-null   float64\n",
      " 50  char_freq_[                 3450 non-null   float64\n",
      " 51  char_freq_!                 3450 non-null   float64\n",
      " 52  char_freq_$                 3450 non-null   float64\n",
      " 53  char_freq_#                 3450 non-null   float64\n",
      " 54  capital_run_length_average  3450 non-null   float64\n",
      " 55  capital_run_length_longest  3450 non-null   int64  \n",
      " 56  capital_run_length_total    3450 non-null   int64  \n",
      "dtypes: float64(55), int64(2)\n",
      "memory usage: 1.5 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.102548</td>\n",
       "      <td>0.203142</td>\n",
       "      <td>0.281264</td>\n",
       "      <td>0.058893</td>\n",
       "      <td>0.305536</td>\n",
       "      <td>0.093319</td>\n",
       "      <td>0.108403</td>\n",
       "      <td>0.104846</td>\n",
       "      <td>0.087788</td>\n",
       "      <td>0.237267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032157</td>\n",
       "      <td>0.037543</td>\n",
       "      <td>0.141913</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>0.269011</td>\n",
       "      <td>0.075221</td>\n",
       "      <td>0.043025</td>\n",
       "      <td>5.075657</td>\n",
       "      <td>53.362899</td>\n",
       "      <td>279.538551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302247</td>\n",
       "      <td>1.252997</td>\n",
       "      <td>0.510124</td>\n",
       "      <td>1.292582</td>\n",
       "      <td>0.675167</td>\n",
       "      <td>0.265308</td>\n",
       "      <td>0.364718</td>\n",
       "      <td>0.408860</td>\n",
       "      <td>0.275744</td>\n",
       "      <td>0.636678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278670</td>\n",
       "      <td>0.237961</td>\n",
       "      <td>0.291371</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.877296</td>\n",
       "      <td>0.235507</td>\n",
       "      <td>0.352593</td>\n",
       "      <td>31.738005</td>\n",
       "      <td>214.256532</td>\n",
       "      <td>571.649170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.586000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.270500</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.051750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.729500</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.730000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>2.777000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>13.129000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>10062.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     3450.000000        3450.000000    3450.000000   3450.000000   \n",
       "mean         0.102548           0.203142       0.281264      0.058893   \n",
       "std          0.302247           1.252997       0.510124      1.292582   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.410000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.730000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    3450.000000     3450.000000       3450.000000         3450.000000   \n",
       "mean        0.305536        0.093319          0.108403            0.104846   \n",
       "std         0.675167        0.265308          0.364718            0.408860   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.360000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  word_freq_conference  \\\n",
       "count      3450.000000     3450.000000  ...           3450.000000   \n",
       "mean          0.087788        0.237267  ...              0.032157   \n",
       "std           0.275744        0.636678  ...              0.278670   \n",
       "min           0.000000        0.000000  ...              0.000000   \n",
       "25%           0.000000        0.000000  ...              0.000000   \n",
       "50%           0.000000        0.000000  ...              0.000000   \n",
       "75%           0.000000        0.160000  ...              0.000000   \n",
       "max           5.260000       18.180000  ...             10.000000   \n",
       "\n",
       "       char_freq_;  char_freq_(  char_freq_[  char_freq_!  char_freq_$  \\\n",
       "count  3450.000000  3450.000000  3450.000000  3450.000000  3450.000000   \n",
       "mean      0.037543     0.141913     0.017116     0.269011     0.075221   \n",
       "std       0.237961     0.291371     0.099000     0.877296     0.235507   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.065000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.186750     0.000000     0.310000     0.051750   \n",
       "max       4.385000     9.752000     2.777000    32.478000     6.003000   \n",
       "\n",
       "       char_freq_#  capital_run_length_average  capital_run_length_longest  \\\n",
       "count  3450.000000                 3450.000000                 3450.000000   \n",
       "mean      0.043025                    5.075657                   53.362899   \n",
       "std       0.352593                   31.738005                  214.256532   \n",
       "min       0.000000                    1.000000                    1.000000   \n",
       "25%       0.000000                    1.586000                    6.000000   \n",
       "50%       0.000000                    2.270500                   14.000000   \n",
       "75%       0.000000                    3.729500                   43.000000   \n",
       "max      13.129000                 1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total  \n",
       "count               3450.000000  \n",
       "mean                 279.538551  \n",
       "std                  571.649170  \n",
       "min                    1.000000  \n",
       "25%                   33.000000  \n",
       "50%                   93.000000  \n",
       "75%                  263.000000  \n",
       "max                10062.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.info()\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.939</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.379</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.644</td>\n",
       "      <td>13</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.055</td>\n",
       "      <td>117</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.007</td>\n",
       "      <td>2.112</td>\n",
       "      <td>26</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4469</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.500</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "1173            0.00                0.0           0.00           0.0   \n",
       "1954            0.67                0.0           0.00           0.0   \n",
       "256             0.00                0.0           1.42           0.0   \n",
       "3341            0.00                0.0           0.24           0.0   \n",
       "4469            0.00                0.0           0.00           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "1173           0.00            0.00              1.23                0.00   \n",
       "1954           0.00            0.00              0.00                0.00   \n",
       "256            0.71            0.00              0.00                0.71   \n",
       "3341           0.09            0.04              0.00                0.00   \n",
       "4469           0.00            0.00              0.00                0.00   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
       "1173             0.00            0.00  ...                   0.0        0.000   \n",
       "1954             0.00            0.00  ...                   0.0        0.000   \n",
       "256              0.00            0.71  ...                   0.0        0.000   \n",
       "3341             0.04            0.00  ...                   0.0        0.014   \n",
       "4469             0.00            0.00  ...                   0.0        0.000   \n",
       "\n",
       "      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "1173        0.000          0.0        1.939        0.000        0.000   \n",
       "1954        0.055          0.0        0.000        0.000        0.000   \n",
       "256         0.000          0.0        0.931        0.000        0.000   \n",
       "3341        0.148          0.0        0.014        0.044        0.007   \n",
       "4469        0.000          0.0        0.000        0.000        0.000   \n",
       "\n",
       "      capital_run_length_average  capital_run_length_longest  \\\n",
       "1173                       1.379                           8   \n",
       "1954                       1.644                          13   \n",
       "256                       12.055                         117   \n",
       "3341                       2.112                          26   \n",
       "4469                       1.500                           2   \n",
       "\n",
       "      capital_run_length_total  \n",
       "1173                        40  \n",
       "1954                        74  \n",
       "256                        217  \n",
       "3341                      1223  \n",
       "4469                         3  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.032</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.320</td>\n",
       "      <td>7</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.548</td>\n",
       "      <td>59</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.745</td>\n",
       "      <td>12</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "3683            0.00                0.0           0.00           0.0   \n",
       "4412            0.71                0.0           0.71           0.0   \n",
       "2584            0.00                0.0           0.91           0.0   \n",
       "69              0.00                0.0           0.00           0.0   \n",
       "1844            0.00                0.0           0.54           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "3683            0.0             0.0               0.0                0.00   \n",
       "4412            0.0             0.0               0.0                0.00   \n",
       "2584            0.0             0.0               0.0                0.45   \n",
       "69              0.0             0.0               0.0                0.00   \n",
       "1844            0.0             0.0               0.0                0.00   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
       "3683              0.0            0.00  ...                   0.0          0.0   \n",
       "4412              0.0            0.71  ...                   0.0          0.0   \n",
       "2584              0.0            0.00  ...                   0.0          0.0   \n",
       "69                0.0            0.00  ...                   0.0          0.0   \n",
       "1844              0.0            0.00  ...                   0.0          0.0   \n",
       "\n",
       "      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "3683        0.000        0.000          0.0          0.0          0.0   \n",
       "4412        0.000        0.000          0.0          0.0          0.0   \n",
       "2584        0.000        0.000          0.0          0.0          0.0   \n",
       "69          0.201        0.000          0.0          0.1          0.0   \n",
       "1844        0.188        0.047          0.0          0.0          0.0   \n",
       "\n",
       "      capital_run_length_average  capital_run_length_longest  \\\n",
       "3683                       1.000                           1   \n",
       "4412                       1.032                           2   \n",
       "2584                       1.320                           7   \n",
       "69                         4.548                          59   \n",
       "1844                       1.745                          12   \n",
       "\n",
       "      capital_run_length_total  \n",
       "3683                         3  \n",
       "4412                        32  \n",
       "2584                       103  \n",
       "69                         141  \n",
       "1844                        89  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `StandardScaler` to scale the features data. Remember that only `X_train` and `X_test` DataFrames should be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training data\n",
    "X_train_scaled = scaler.transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit a Logistic Regression Model\n",
    "\n",
    "Create a Logistic Regression model, fit it to the training data, make predictions with the testing data, and print the model's accuracy score. You may choose any starting settings you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model and print the model score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisticRegression_model = LogisticRegression(max_iter=500, random_state=1)\n",
    "lr_model=LogisticRegression_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make and save testing predictions with the saved logistic regression model using the test data\n",
    "testing_predections = lr_model.predict(X_test)\n",
    "# Review the predictions\n",
    "testing_predections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Testing Score: 92.26759%\n",
      "Logistic Regression Training Score: 92.57971%\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Testing Score: {lr_model.score(X_test_scaled, y_test)*100:.5f}%')\n",
    "print(f'Logistic Regression Training Score: {lr_model.score(X_train_scaled, y_train)*100:.5f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score: 92.26759%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score by evaluating `y_test` vs. `testing_predictions`.\n",
    "accuracy_score(y_test, lr_model.predict(X_test_scaled))\n",
    "print(f\"Logistic Regression Accuracy Score: {accuracy_score(y_test, lr_model.predict(X_test_scaled))*100:.5f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit a Random Forest Classifier Model\n",
    "\n",
    "Create a Random Forest Classifier model, fit it to the training data, make predictions with the testing data, and print the model's accuracy score. You may choose any starting settings you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Score: 99.94203%\n",
      "Random Forest Testing Score: 95.56907%\n"
     ]
    }
   ],
   "source": [
    "# Make and save testing predictions with the saved logistic regression model using the test data\n",
    "rf_class = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Review the predictions\n",
    "print(f'Random Forest Training Score: {rf_class.score(X_train_scaled, y_train)*100:.5f}%')\n",
    "print(f'Random Forest Testing Score: {rf_class.score(X_test_scaled, y_test)*100:.5f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 95.56907%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score by evaluating `y_test` vs. `testing_predictions`.\n",
    "accuracy_score(y_test, rf_class.predict(X_test_scaled))\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, rf_class.predict(X_test_scaled)) * 100:.5f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Models\n",
    "\n",
    "Which model performed better? How does that compare to your prediction? Write down your results and thoughts in the following markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which model performed better?\n",
    "    - While both models were properly fit, the Random Forest model had a 3.30148% higher accuracy rating and is therefore the better model to run.\n",
    "### How does that compare to your prediction?\n",
    "    - My initial intution was correct, the RForest model out performed the LRegresssion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model\n",
      "Logistic Regression Training Score: 92.57971%\n",
      "Logistic Regression Testing Score: 92.26759%\n",
      "Logistic Regression Accuracy Score: 92.26759%\n",
      "Random Forest Model\n",
      "Random Forest Training Score: 99.94203%\n",
      "Random Forest Testing Score: 95.56907%\n",
      "Random Forest Accuracy: 95.56907%\n"
     ]
    }
   ],
   "source": [
    "print ('Logistic Regression Model')\n",
    "print(f'Logistic Regression Training Score: {lr_model.score(X_train_scaled, y_train)*100:.5f}%')\n",
    "print(f'Logistic Regression Testing Score: {lr_model.score(X_test_scaled, y_test)*100:.5f}%')\n",
    "print(f\"Logistic Regression Accuracy Score: {accuracy_score(y_test, lr_model.predict(X_test_scaled))*100:.5f}%\")\n",
    "print('Random Forest Model'  )\n",
    "print(f'Random Forest Training Score: {rf_class.score(X_train_scaled, y_train)*100:.5f}%')\n",
    "print(f'Random Forest Testing Score: {rf_class.score(X_test_scaled, y_test)*100:.5f}%')\n",
    "\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, rf_class.predict(X_test_scaled)) * 100:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference in accuracy is 3.30148 %\n"
     ]
    }
   ],
   "source": [
    "print(f'The difference in accuracy is {(accuracy_score(y_test, rf_class.predict(X_test_scaled)) * 100 - accuracy_score(y_test, lr_model.predict(X_test_scaled)) * 100):.5f} %')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
